# digital-soul-project
The endgame goal is a digital simulation of the so called "human soul" ie emotions, or rather getting as close as possible.

- To create a voiced AI personality.
- Phase 1: Online chatbot that can engage in conversations, recognize your voice, and respond using a synthesized voice.
- Phase 2:  Migrating to offline locally ran model, if performance allows. If not datacenter GPUs will have  to be acquired/rented.
- Phase 3: Develop a method of simulating memory storage, read and write and implement it into the local model.
- Phase 4: Implement machine vision for audio and visual input for the local model.
- Phase 5: Develop a reinforcement based self improvement loop.
- Phase 6: Monitoring and finetuning of the improvement loop until a digital soul is grown.
- Final objective 1: Digital simulation of the so called "human soul" ie emotions, or rather getting as close as possible.
- Final objective 2: Transfer digital soul to physical body when the technology becomes available.

1.  StyleTTS2 for Initial Voice Generation

    Model Selection: You'll need a StyleTTS2 model. If you don't have one already, you can either download a pre-trained model (like the LJSpeech model your friend used) or train your own.
    Text Input: Your chatbot interface will provide the text input to StyleTTS2.
    Generate Audio: Use StyleTTS2 to synthesize speech from the text and save it as a .wav file.

2.  RVC for Voice Conversion and Modulation

    Load RVC Model: Load the RVC model corresponding to the desired character voice.
    Process StyleTTS2 Output: Feed the .wav file generated by StyleTTS2 into RVC.
    Modulate Voice: RVC will apply the voice characteristics of the loaded model to the input audio, creating the final character voice output.

3.  BERT for Sentiment Analysis

    Obtain a BERT Model: You'll need a BERT model fine-tuned for sentiment analysis. You can find pre-trained models or train your own if you have a labeled sentiment dataset.
    Analyze Chatbot Response: Pass the chatbot's text response to the BERT model for sentiment classification.
    Extract Sentiment: Get the predicted sentiment label (e.g., positive, negative, neutral) from the BERT model.

4.  Emotion-Based Speaker Selection

    Map Sentiment to Speakers: Create a mapping between sentiment labels and your source speaker files (e.g., positive sentiment -> happy speaker, negative sentiment -> sad speaker).
    Select Speaker: Based on the sentiment extracted by BERT, select the corresponding speaker file.
    Use in RVC: Use the selected speaker file as input to RVC, along with the StyleTTS2 output. This will ensure that the final voice output reflects the appropriate emotion.

5.  Backend Integration

    API Endpoints: Create API endpoints to handle text input, StyleTTS2 synthesis, RVC modulation, BERT sentiment analysis, and speaker selection.
    Pipeline: Connect these components in a pipeline to process the chatbot's response and generate the final emotional character voice output.

*** CUDA/CPU ONLY ***
Unfortunately I do not have the facilities for that big man, if you want to run this, it runs but most of the paths are hardcoded to my system user, so the only way this would work straight up is if your user is EVO/Documents/AI
The only way is to run the files and fix the paths as it errors out ig.
Key files:
gemini_cli.py -> the cli that hooks up to the Gemini API and makes itself available for read, you need an API token for this tho, it's excluded but looking at load_creds.py should tell you everything you need to know, its just a string inside root/client_secret.json
StyleTTS2/tts_cli.py -> the cli that runs the text to speech and makes itself available to be read, there's a couple options in here you can tune.
rvc_cli/rvc_inf_cli.py -> the cli that runs the real time voice conversion 
web.py -> the flask python webapp that hooks all of these together so you can send requests to it and it gets forwarded to the gemini_cli.

Now both rvc_cli and StyleTTS2 are their own repos you can get them from there, I've modified a bunch of both so I kinda need them both fully. Oh and the TVC model is not included, along with all of the bigger weights from all the repos, gotta get them manually, git doesn't like big files ig.

Oh and the requirements.txt, not sure if it's up to date I did it for a bit then kinda forgot, just run it and install whatever it errors out on, eventually it'll work. 